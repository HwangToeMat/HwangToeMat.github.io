---
title: 2. FaceNet 논문 리뷰
image: https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img0.jpg?raw=true
description: >
 FaceNet - A Unified Embedding for Face Recognition and Clustering을 읽고 논문 주요내용을 정리해본다.
author: author1
layout: post
order: 16
---
# [Face Recognition] 2. FaceNet 논문 리뷰

<a href="https://arxiv.org/abs/1503.03832.pdf">[PDF] 논문원본</a>

# FaceNet: A Unified Embedding for Face Recognition and Clustering

## 모델 설명

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img6.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

**FaceNet**은 각각의 얼굴 이미지를 **128차원으로 임베딩**하여 **유클리드 공간**에서 이미지간의 거리(까울 수록 유사도가 높음)를 통해 분류하는 모델이다. 


간단히 말하면 얼굴 사진에서 그 사람에 대한 특징값을 구해주는 모델이고, 그 값을 활용하여 값들간의 거리를 통해 이미지에 대한 **identification, verification, clustering**을 할 수 있게 되는 것이다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img7.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

이때 **triplet loss를 사용한 Metric Learning**으로 모델을 학습하였는데 이는 매우 중요하기 때문에 아래에서 더 자세히 다루어 보도록 하겠다. 


추가적으로 **기존의 모델들이 2D나 3D로 aligned된 얼굴 이미지를 필요**로 하였던 것에 비해 **FaceNet은 그러한 과정없이 높은 성능**이 나왔다는 점 또한 모델 설계가 얼마나 정교하게 이루어졌는지 나타내는 요소 중 하나라고 생각한다.~~(물론, 얼굴크기에 맟게 잘라주는 과정은 필요하고 추가적인 aligned 과정은 성능을 올려준다.)~~

## Triplet Loss를 사용한 Metric Learning

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img1.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

FaceNet은 학습과정에서 **Metric Learning을 하기위해 Triplet Loss를 사용**했다. 학습시 미니배치안에서 **어떠한 사람(Anchor)에** 대해 **같은 사람(Positive)와** **다른 사람(Negative)를** 지정해 놓는다. 그리고 임베딩된 값들의 유클리드 거리를 구해 그림과 같이 **Anchor와 Positive의 거리는 가까워**지고 **Negative와의 거리는 멀어지**도록 학습을 시켰고 이러한 과정을 triplet loss로 구현하였다.  

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img2.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

즉, 앞서말한 과정을 식으로 나타내면 위와 같다. 대괄호 안의 **첫 번째 항**이 의미하는 것은 **Positive와의 거리**이고 **두 번째 항**은 **Negative와의 거리**이며 **alpha는 마진**을 의미한다. 따라서 **L을 최소화**한다는 의미는 Positive의 거리는 가까워지도록 하고 Negative와의 거리는 멀어지도록 한다는 것이다.


하지만 모델의 성능을 높이기 위해서는 **Hard Positive(같은 사람이지만 다르게 보이는 사람)과 Hard Negative(다른 사람이지만 닮은 사람)와** 같이 학습을 방해하는 요소를 **제어**할 필요가 있었고, 이러한 문제를 해결하기위해 아래와 같은 식을 사용하였다. 

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img3.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

**Hard Positive는 위의 첫 번째 식**과같이 나타낼 수 있고, **Hard Negative는 두 번째 식**과 같이 나타낼 수 있는데, 이 모델에서는 **Hard Positive는 전부 학습**을 진행하였지만 **Hard Negative**는 **세 번째 식을 만족할 경우에만 학습**을 진행하였다.

## 모델 구조

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img8.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

위의 그래프는 FaceNet의 **여러 구조들이 갖는 성능**을 비교한 그래프이다. 각각의 특징은 오른쪽에 나와있는 표와 같다. 그 중 **가장 성능이 좋아 보이는 NN2(Inception 224x224)의** 자세한 구조를 살펴보면 아래와 같다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img9.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

## 모델 성능
### LFW dataset에서의 모델성능

얼굴 크기에 맞게 잘라주는 과정만 했을때는 LFW에서 **98.87%의 정확도**를 보였고, 추가적인 alignment를 했을 경우에는 **99.63%까지** 정확도가 오르는 것을 볼 수 있었다.


**아래의 이미지는 FaceNet이 맞추지 못한 이미지**이다. 사실 몇개는 인간이 보기에도 알아보기 힘들정도기 때문에 모델의 성능이 대단히 높다는 것을 알 수 있다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img4.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

### 클러스터링 성능

**클러스터링**을 통해 같은 사람끼리 모아 놓았다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img5.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">
