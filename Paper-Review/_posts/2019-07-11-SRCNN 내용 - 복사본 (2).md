---
title: 3-1. SRGAN 논문 리뷰
image: https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/assets/img/thumbnail/pr-3-1.jpg?raw=true
description: >
 SRCNN - Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network을 읽고 논문 주요내용을 정리해본다.
author: author1
layout: post
order: 6
---

<a href="https://arxiv.org/abs/1609.04802">[PDF] 논문원본</a>

## Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network

### 모델 구조

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/assets/img/thumbnail/pr-1.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

그림과 같이 3개의 layer로 이루어져있고, 각각 9\*9, 1\*1, 5\*5사이즈의 커널로 이루어져 있다. 저해상도의 이미지가 3개의 layer를 지나 고해상도의 이미지를 출력하게 된다.

### 기존의 방법과 비교

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-2.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

위의 그래프를 통해 확인 할 수 있듯이 PSNR값을 비교해 봤을때 기존의 방법인 SC나 Bicubic보다 훨씬 높은 성능을 갖는것을 알 수 있다.

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-4.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

PSNR은 아래와 같은 식으로 구할 수 있으며, 신호가 가질 수 있는 최대 전력에 대한 잡음의 전력이라고 정의되어 있으며 최대값에 대한 노이즈의 값이기 때문에 값이 높을 수록 해상도가 높은 것으로 볼 수 있다. 

### Loss function

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-3.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

학습과정에서는 MSE(평균오차제곱)을 Loss function으로 사용하였다.

### 실험

* 데이터 양에 따른 PSNR 비교

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-5.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

* 커널 사이즈에 따른 PSNR 비교

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-6.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

* layer의 깊이에 따른 PSNR 비교

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-7.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

결론적으로 더 많은 데이터, 더 큰 커널사이즈, 더 얕은 layer 깊이 일 수록 좋은 성능을 갖는 것을 알 수 있지만 학습이 오래걸리는 것에 비해 차이가 크지 않다는 것 또한 알 수 있다.

### 실험 결과

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-8.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">
