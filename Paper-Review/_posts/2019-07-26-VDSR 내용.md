---
title: 2-1. VDSR 논문 리뷰
image: https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/assets/img/thumbnail/pr-2-1.jpg?raw=true
description: >
 VDSR - Accurate Image Super-Resolution Using Very Deep Convolutional Networks을 읽고 논문 주요내용을 정리해본다.
author: author1
layout: post
order: 4
---

<a href="https://cv.snu.ac.kr/research/VDSR/VDSR_CVPR2016.pdf">[PDF] 논문원본</a>

## Accurate Image Super-Resolution Using Very Deep Convolutional Networks

### 모델 구조

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/assets/img/thumbnail/pr-2-1.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

그림과 같이 총 20개의 layer로 이루어져있고, 각각 3\*3사이즈의 커널로 이루어져 있다. 특이한 점은 19개의 layer를 지나 만들어진 residual(r)값과 skip-connection을 통해 지나온 ILR(x)을 더 하여 고화질의 HR을 출력하는 방식이다. 위의 방법을 통해 기존의 얕은 층 모델에서 깊은 층 모델로 진화할 수 있게 되었다. 

### 기존의 방법과 비교

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image1.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

위의 그래프를 통해 확인 할 수 있듯이 PSNR값을 비교해 봤을때 기존의 방법인 SRCNN보다 훨씬 높은 성능을 갖는것을 알 수 있다.

<img src="https://github.com/HwangToeMat/SRCNN_Pytorch_HTM/blob/master/image/img-4.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

PSNR은 아래와 같은 식으로 구할 수 있으며, 신호가 가질 수 있는 최대 전력에 대한 잡음의 전력이라고 정의되어 있으며 최대값에 대한 노이즈의 값이기 때문에 값이 높을 수록 해상도가 높은 것으로 볼 수 있다. 

### Loss function

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image2.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

모델의 구조에서 알 수 있듯이 residual image(r)은 r = y - x(y는 HR, x는 LR이다.)로 정의할 수 있고 이때 좋은 모델 이려면 r값이 최소가 되도록 해야한다. 따라서 loss function은 위와 같이 나타낼 수 있다.

### 실험

* 데이터 양에 따른 PSNR 비교

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image3.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

* 커널 사이즈에 따른 PSNR 비교

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image4.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

* layer의 깊이에 따른 PSNR 비교

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image5.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

결론적으로 더 많은 데이터, 더 큰 커널사이즈, 더 얕은 layer 깊이 일 수록 좋은 성능을 갖는 것을 알 수 있지만 학습이 오래걸리는 것에 비해 차이가 크지 않다는 것 또한 알 수 있다.

### 실험 결과

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image6.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/VDSR/image7.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">
