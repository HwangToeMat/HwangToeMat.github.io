---
title: 03. 가벼운 Super-Resolution 모델 개발 - Asym VDSR
image: https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/AI-Project/image/AsymVDSR/img1.png?raw=true
description: >
 Asymmetric convolution을 사용하여 기존의 Super-Resolution 모델들의 특징과 성능을 유지하고 적은 수의 파라미터로 Super-Resolution 문제를 해결한다.
author: author1
layout: post
order: 4
---
# Super-Resolution with fewer parameters by using Asymmetric convolution

<a href="https://github.com/HwangToeMat/Asym_VDSR">[Github] 코드 원본</a>

## 연구 주제 

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/AI-Project/image/AsymVDSR/img2.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

**Asymmetric convolution**을 사용하여 기존의 Super-Resolution 모델들의 특징과 성능을 유지하고 **적은 수의 파라미터**로 Super-Resolution 문제를 해결한다.

## 관련 연구

1. VDSR

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/AI-Project/image/AsymVDSR/img3.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

> * Accurate Image Super-Resolution Using Very Deep Convolutional Networks, Seoul National University, Korea (CVPR 2016)
>
> * 20개의 층으로 이루어진 딥러닝 모델
>
> * residual 값과 skip connection을 지나온 LR을 더해서 SR을 생성
>
> * 실험의 Baseline model로 사용

2. Asymmetric Convolution

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/AI-Project/image/AsymVDSR/img4.png?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

> * kernel이 n\*n의 형태가 아니라 m\*n형태의 비대칭 형태인 convolution 연산
>
> * 그림과 같이 3\*3 크기의 영역을 1\*1로 축소할 때 3\*1, 1\*3 두번의 연산으로 변경 가능(기존의 9개의 파라미터를 6개로 축소)
>
> * 크기가 큰 영역을 축소시킬 수록 더 크게 감소


## Triplet Loss를 사용한 Metric Learning

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img1.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

FaceNet은 학습과정에서 **Meric Learning을 하기위해 Triplet Loss를 사용**했다. 학습시 미니배치안에서 **어떠한 사람(Anchor)에** 대해 **같은 사람(Positive)와** **다른 사람(Negative)를** 지정해 놓는다. 그리고 임베딩된 값들의 유클리드 거리를 구해 그림과 같이 **Anchor와 Positive의 거리는 가까워**지고 **Negative와의 거리는 멀어지**도록 학습을 시켰고 이러한 과정을 triplet loss로 구현하였다.  

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img2.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

즉, 앞서말한 과정을 식으로 나타내면 위와 같다. 대괄호 안의 **첫 번째 항**이 의미하는 것은 **Positive와의 거리**이고 **두 번째 항**은 **Negative와의 거리**이며 **alpha는 마진**을 의미한다. 따라서 **L을 최소화**한다는 의미는 Positive의 거리는 가까워지도록 하고 Negative와의 거리는 멀어지도록 한다는 것이다.


하지만 모델의 성능을 높이기 위해서는 **Hard Positive(같은 사람이지만 다르게 보이는 사람)과 Hard Negative(다른 사람이지만 닮은 사람)와** 같이 학습을 방해하는 요소를 **제어**할 필요가 있었고, 이러한 문제를 해결하기위해 아래와 같은 식을 사용하였다. 

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img3.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

**Hard Positive는 위의 첫 번째 식**과같이 나타낼 수 있고, **Hard Negative는 두 번째 식**과 같이 나타낼 수 있는데, 이 모델에서는 **Hard Positive는 전부 학습**을 진행하였지만 **Hard Negative**는 **세 번째 식을 만족할 경우에만 학습**을 진행하였다.

## 모델 구조

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img8.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

위의 그래프는 FaceNet의 **여러 구조들이 갖는 성능**을 비교한 그래프이다. 각각의 특징은 오른쪽에 나와있는 표와 같다. 그 중 **가장 성능이 좋아 보이는 NN2(Inception 224x224)의** 자세한 구조를 살펴보면 아래와 같다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img9.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

## 모델 성능
### LFW dataset에서의 모델성능

얼굴 크기에 맞게 잘라주는 과정만 했을때는 LFW에서 **98.87%의 정확도**를 보였고, 추가적인 alignment를 했을 경우에는 **99.63%까지** 정확도가 오르는 것을 볼 수 있었다.


**아래의 이미지는 FaceNet이 맞추지 못한 이미지**이다. 사실 몇개는 인간이 보기에도 알아보기 힘들정도기 때문에 모델의 성능이 대단히 높다는 것을 알 수 있다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img4.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">

### 클러스터링 성능

**클러스터링**을 통해 같은 사람끼리 모아 놓았다.

<img src="https://github.com/HwangToeMat/HwangToeMat.github.io/blob/master/Paper-Review/image/FaceNet/img5.jpg?raw=true" style="max-width:100%;margin-left: auto; margin-right: auto; display: block;">
